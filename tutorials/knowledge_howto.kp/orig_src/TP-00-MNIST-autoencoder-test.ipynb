{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Using Convolutional Autoencoder for Clustering (new title)\n",
    "authors:\n",
    "- tanelp\n",
    "tags:\n",
    "- autoencoder\n",
    "- coffee-machine\n",
    "created_at: 2018-02-27\n",
    "updated_at: 2018-03-01\n",
    "tldr: The goal of this notebook is to test whether it is possible to use encoder part of autoencoder for clustering. The idea is to train an autoencoder, where the final layer of encoder (and first layer of decoder), is a n-dimensional vector, where n corresponds to number of clusters. The encoder could then be used for predicting to which cluster the input image belongs to.\n",
    "\n",
    "The MNIST dataset is used in this case. The code is based on the following tutorial: https://blog.keras.io/building-autoencoders-in-keras.html. The encoder was changed by flattening the (4, 4, 8) tensor (or layer) to a 128-dimensional layer and then adding fully connected layer with 10 neurons (one for each MNIST number). \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Convolutional Autoencoder for clustering\n",
    "The goal of this notebook is to test whether it is possible to use encoder part of autoencoder for clustering. The idea is to train an autoencoder, where the final layer of encoder (and first layer of decoder), is a n-dimensional vector, where n corresponds to number of clusters. The encoder could then be used for predicting to which cluster the input image belongs to.\n",
    "\n",
    "The MNIST dataset is used in this case. The code is based on the following tutorial: https://blog.keras.io/building-autoencoders-in-keras.html. The encoder was changed by flattening the (4, 4, 8) tensor (or layer) to a 128-dimensional layer and then adding fully connected layer with 10 neurons (one for each MNIST number). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "print(K.int_shape(x))\n",
    "x = Flatten()(x)\n",
    "print(K.int_shape(x))\n",
    "encoded = Dense(10, activation='relu')(x)\n",
    "\n",
    "\n",
    "x = Dense(128, activation='relu')(encoded)\n",
    "x = Reshape((4, 4, 8))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "encoder = Model(input_img, encoded)\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=2,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                verbose=0,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find class indexes\n",
    "\n",
    "We predict the activity of neurons in the last encoder layer for each training sample and for each sample find which neuron was the most active. We then find images which were clustered into the first cluster (predicted_classes==1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_classes = np.argmax(encoder.predict(x_train), axis=1)\n",
    "class_indexes = [idx[0] for idx in np.argwhere(predicted_classes==1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize images from one predicted cluster\n",
    "Ten first images frome one cluster are then visualized. Ideally, being in one cluster, the following images should all be the same numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "j = 1\n",
    "for i in class_indexes[:10]:\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, j)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    j += 1\n",
    "\n",
    "    # display reconstruction\n",
    "#     ax = plt.subplot(2, n, j + n)\n",
    "#     plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "#     plt.gray()\n",
    "#     ax.get_xaxis().set_visible(False)\n",
    "#     ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "It seems that convolutional autoencoders by themselves are not very good at clustering images. It might be possible to use the encoder predictions as features for classical clustering algorithms, such as K-means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder + k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "X = encoder.predict(x_train)\n",
    "kmeans = KMeans(n_clusters=8, random_state=0).fit(X)\n",
    "kmeans.labels_\n",
    "\n",
    "#kmeans.predict([[0, 0], [4, 4]])\n",
    "\n",
    "#kmeans.cluster_centers_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indexes = [idx[0] for idx in np.argwhere(kmeans.labels_==2)]\n",
    "\n",
    "n = 8\n",
    "plt.figure(figsize=(20, 4))\n",
    "j = 1\n",
    "for i in class_indexes[:10]:\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, j)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    j += 1\n",
    "\n",
    "    # display reconstruction\n",
    "#     ax = plt.subplot(2, n, j + n)\n",
    "#     plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "#     plt.gray()\n",
    "#     ax.get_xaxis().set_visible(False)\n",
    "#     ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}